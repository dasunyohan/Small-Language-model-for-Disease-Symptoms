{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: torchtext in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.18.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.40.2)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.66.2)\n",
      "Requirement already satisfied: datasets in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.19.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchtext) (2.31.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchtext) (1.26.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.23.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\outis lupin\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2024.4.28)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\outis lupin\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\outis lupin\\appdata\\roaming\\python\\python312\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (15.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\outis lupin\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torchtext) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torchtext) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torchtext) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torchtext) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\outis lupin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchtext transformers sentencepiece pandas tqdm datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Outis Lupin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "import pandas as pd\n",
    "import ast\n",
    "import datasets\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "#load dataset\n",
    "db = load_dataset(\"QuyenAnhDE/Diseases_Symptoms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Code', 'Name', 'Symptoms', 'Treatments'],\n",
       "        num_rows: 400\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_db = [{'Name':item['Name'], 'Symptoms':item['Symptoms']} for item in db['train']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(updated_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Symptoms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Panic disorder</td>\n",
       "      <td>Palpitations, Sweating, Trembling, Shortness o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vocal cord polyp</td>\n",
       "      <td>Hoarseness, Vocal Changes, Vocal Fatigue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turner syndrome</td>\n",
       "      <td>Short stature, Gonadal dysgenesis, Webbed neck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cryptorchidism</td>\n",
       "      <td>Absence or undescended testicle(s), empty scro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ethylene glycol poisoning-1</td>\n",
       "      <td>Nausea, vomiting, abdominal pain, General mala...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Name  \\\n",
       "0               Panic disorder   \n",
       "1             Vocal cord polyp   \n",
       "2              Turner syndrome   \n",
       "3               Cryptorchidism   \n",
       "4  Ethylene glycol poisoning-1   \n",
       "\n",
       "                                            Symptoms  \n",
       "0  Palpitations, Sweating, Trembling, Shortness o...  \n",
       "1           Hoarseness, Vocal Changes, Vocal Fatigue  \n",
       "2  Short stature, Gonadal dysgenesis, Webbed neck...  \n",
       "3  Absence or undescended testicle(s), empty scro...  \n",
       "4  Nausea, vomiting, abdominal pain, General mala...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the symptoms feature/column\n",
    "df['Symptoms'] = df['Symptoms'].apply(lambda x: ', '.join(x.split(', ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up the device with cuda or cpu\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Outis Lupin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('distilgpt2').to(device)\n",
    "#force_download=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Symptoms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>392</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Sciatica</td>\n",
       "      <td>Swelling, pain, dry mouth, bad taste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name                              Symptoms\n",
       "count        400                                   400\n",
       "unique       392                                   395\n",
       "top     Sciatica  Swelling, pain, dry mouth, bad taste\n",
       "freq           3                                     3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.labels = df.columns \n",
    "        self.data = df.to_dict(orient='records')\n",
    "        self.tokenizer = tokenizer\n",
    "        x = self.fittest_max_length(df)\n",
    "        self.max_length = x\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx][self.labels[0]]\n",
    "        y = self.data[idx][self.labels[1]]\n",
    "        text = f\"{x} | {y}\"\n",
    "        tokens = self.tokenizer.encode_plus(text, return_tensors = 'pt', max_length=128, padding='max_length', truncation=True)\n",
    "        return tokens\n",
    "    \n",
    "    def fittest_max_length(self, df):\n",
    "        max_length = max(len(max(df[self.labels[0]], key=len)), len(max(df[self.labels[1]], key=len)))\n",
    "        x = 2\n",
    "        while x < max_length: x = x * 2\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = LanguageDataset(df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LanguageDataset at 0x29c9ed4db20>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(data_sample))\n",
    "val_size = len(data_sample) - train_size\n",
    "\n",
    "train_data, val_data = random_split(data_sample, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = BATCH_SIZE\n",
    "model_name = 'distilgpt2'\n",
    "gpu = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the learning rate and loss function\n",
    "## CrossEntropyLoss measures how close answers to the truth.\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index= tokenizer.pad_token_id)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['epoch','transformer','batch_size', 'gpu', 'training_loss', 'validation_loss', 'epoch_duration_sec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1/8 Batch Size: 8, Transformer:distilgpt2: 100%|██████████| 40/40 [03:17<00:00,  4.94s/it, Training Loss=0.581]\n",
      "validating epoch 1/8: 100%|██████████| 10/10 [00:14<00:00,  1.50s/it, Validation Loss=<built-in method item of Tensor object at 0x0000029CA10E3F20>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Validation Loss: 0.693556547164917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 2/8 Batch Size: 8, Transformer:distilgpt2: 100%|██████████| 40/40 [03:07<00:00,  4.70s/it, Training Loss=0.405]\n",
      "validating epoch 2/8: 100%|██████████| 10/10 [00:14<00:00,  1.47s/it, Validation Loss=<built-in method item of Tensor object at 0x0000029CA1125400>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Validation Loss: 0.664656937122345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 3/8 Batch Size: 8, Transformer:distilgpt2: 100%|██████████| 40/40 [03:08<00:00,  4.70s/it, Training Loss=0.484]\n",
      "validating epoch 3/8: 100%|██████████| 10/10 [00:14<00:00,  1.45s/it, Validation Loss=<built-in method item of Tensor object at 0x0000029CA1131E00>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Validation Loss: 0.6815203428268433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 4/8 Batch Size: 8, Transformer:distilgpt2: 100%|██████████| 40/40 [03:14<00:00,  4.86s/it, Training Loss=0.297]\n",
      "validating epoch 4/8: 100%|██████████| 10/10 [00:15<00:00,  1.50s/it, Validation Loss=<built-in method item of Tensor object at 0x0000029CA1116C10>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Validation Loss: 0.7225879430770874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 5/8 Batch Size: 8, Transformer:distilgpt2: 100%|██████████| 40/40 [03:12<00:00,  4.81s/it, Training Loss=0.24] \n",
      "validating epoch 5/8: 100%|██████████| 10/10 [00:14<00:00,  1.49s/it, Validation Loss=<built-in method item of Tensor object at 0x0000029CA10EC1E0>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Validation Loss: 0.757003664970398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 6/8 Batch Size: 8, Transformer:distilgpt2: 100%|██████████| 40/40 [03:03<00:00,  4.58s/it, Training Loss=0.325]\n",
      "validating epoch 6/8: 100%|██████████| 10/10 [00:14<00:00,  1.45s/it, Validation Loss=<built-in method item of Tensor object at 0x0000029CA1145270>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Validation Loss: 0.8033286929130554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 7/8 Batch Size: 8, Transformer:distilgpt2: 100%|██████████| 40/40 [03:03<00:00,  4.59s/it, Training Loss=0.126]\n",
      "validating epoch 7/8: 100%|██████████| 10/10 [00:14<00:00,  1.45s/it, Validation Loss=<built-in method item of Tensor object at 0x0000029CA1131450>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Validation Loss: 0.8658673167228699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 8/8 Batch Size: 8, Transformer:distilgpt2: 100%|██████████| 40/40 [03:03<00:00,  4.59s/it, Training Loss=0.145] \n",
      "validating epoch 8/8: 100%|██████████| 10/10 [00:14<00:00,  1.44s/it, Validation Loss=<built-in method item of Tensor object at 0x0000029CA1133750>]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Validation Loss: 0.901246190071106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# The training loop\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()  # Start the timer for the epoch\n",
    "\n",
    "    # Training\n",
    "    ## This line tells the model we're in 'learning mode'\n",
    "    model.train()\n",
    "    epoch_training_loss = 0\n",
    "    train_iterator = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs} Batch Size: {batch_size}, Transformer: {model_name}\")\n",
    "    for batch in train_iterator:\n",
    "        optimizer.zero_grad()\n",
    "        inputs = batch['input_ids'].squeeze(1).to(device)\n",
    "        targets = inputs.clone()\n",
    "        outputs = model(input_ids=inputs, labels=targets)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_iterator.set_postfix({'Training Loss': loss.item()})\n",
    "        epoch_training_loss += loss.item()\n",
    "    avg_epoch_training_loss = epoch_training_loss / len(train_iterator)\n",
    "\n",
    "    # Validation\n",
    "    ## This line below tells the model to 'stop learning'\n",
    "    model.eval()\n",
    "    epoch_validation_loss = 0\n",
    "    total_loss = 0\n",
    "    valid_iterator = tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}/{num_epochs}\")\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_iterator:\n",
    "            inputs = batch['input_ids'].squeeze(1).to(device)\n",
    "            targets = inputs.clone()\n",
    "            outputs = model(input_ids=inputs, labels=targets)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss\n",
    "            valid_iterator.set_postfix({'Validation Loss': loss.item()})\n",
    "            epoch_validation_loss += loss.item()\n",
    "\n",
    "    avg_epoch_validation_loss = epoch_validation_loss / len(val_loader)\n",
    "\n",
    "    end_time = time.time()  # End the timer for the epoch\n",
    "    epoch_duration_sec = end_time - start_time  # Calculate the duration in seconds\n",
    "\n",
    "    new_row = {'transformer': model_name,\n",
    "               'batch_size': batch_size,\n",
    "               'gpu': gpu,\n",
    "               'epoch': epoch+1,\n",
    "               'training_loss': avg_epoch_training_loss,\n",
    "               'validation_loss': avg_epoch_validation_loss,\n",
    "               'epoch_duration_sec': epoch_duration_sec}  # Add epoch_duration to the dataframe\n",
    "\n",
    "    results.loc[len(results)] = new_row\n",
    "    print(f\"Epoch: {epoch+1}, Validation Loss: {total_loss/len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have faced overfittig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performing(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = \"Depression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(input_str, return_tensors='pt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12156,  2234]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(\n",
    "    input_ids,\n",
    "    max_length=20,\n",
    "    num_return_sequences = 1,\n",
    "    do_sample = True,\n",
    "    top_k=8,\n",
    "    top_p=0.95,\n",
    "    temperature=0.5,\n",
    "    repetition_penalty=1.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12156,  2234,   930,  2275,  3438,  1292,  2356,    11, 24924,   803,\n",
       "            11,  2458,   287, 35711,  8650, 50256]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depression | Abdominal pain, bloating, changes in bowel movements\n"
     ]
    }
   ],
   "source": [
    "decoded_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'DiseaseSLM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
